# Claude Code v2.1.32 + Opus 4.6 - Novedades relevantes

## Opus 4.6 - Modelo

### Contexto y tokens

| Concepto | Valor | Notas |
|----------|-------|-------|
| Context window | 1M tokens (beta) | Primer Opus con 1M |
| Output máximo | 128k tokens | Antes era menor |
| Pricing estándar | $5/$25 por M tokens | Input/Output |
| Pricing premium | $10/$37.50 por M tokens | Aplica si input > 200k |
| Plan Pro/Max | ~200k contexto | No se amplía automáticamente a 1M |

**Importante**: El modelo *soporta* 1M, pero tu plan define el límite real. Con Pro/Max sigues en ~200k. El 1M es accesible vía API con pricing premium.

### Mejoras clave
- **Planificación**: piensa más profundo, revisa su razonamiento antes de responder
- **Codebases grandes**: mejor navegación y cambios en proyectos multi-millón de líneas
- **Sesiones largas**: mantiene coherencia por más tiempo sin "context rot"
- **Code review**: detecta sus propios errores mejor
- **Long-context**: en MRCR v2 (needle-in-haystack 1M), 76% vs 18.5% de Sonnet 4.5

### Effort levels (nuevo)

Control de cuánto "piensa" el modelo:

| Nivel | Uso |
|-------|-----|
| `low` | Minimiza thinking, lo salta en tareas simples |
| `medium` | Thinking moderado, puede saltarlo en queries simples |
| `high` | Default, siempre piensa, razonamiento profundo |
| `max` | Siempre piensa sin límite (solo Opus 4.6) |

**Cómo configurar en Claude Code:**
```bash
# Variable de entorno (antes de lanzar sesión)
CLAUDE_CODE_EFFORT_LEVEL=medium claude

# O exportar en shell profile para que aplique siempre
export CLAUDE_CODE_EFFORT_LEVEL=medium
```

**No hay `/effort` interactivo** -- no se puede cambiar en medio de una sesión. Se configura antes de iniciar.

**Tip**: Si Opus 4.6 "piensa demasiado" en tareas simples, lanzar con `medium` ahorra tokens y latencia.

### Adaptive thinking

Claude Opus 4.6 usa adaptive thinking por defecto. En vez de un presupuesto fijo de tokens para "pensar", el modelo decide dinámicamente cuándo y cuánto razonar según la complejidad de cada request.

**Cómo funciona:**
- El modelo evalúa la complejidad de cada petición
- Decide si necesita extended thinking o no
- Con `high`/`max`: casi siempre piensa
- Con `medium`: piensa solo en problemas moderados+
- Con `low`: minimiza, salta thinking en tareas simples
- **Interleaved thinking**: puede pensar *entre* tool calls (clave para workflows agentic)

**Relación con versiones anteriores:**
- `thinking.type: "enabled"` + `budget_tokens` → **deprecated** en Opus 4.6
- `thinking.type: "adaptive"` → nuevo estándar para Opus 4.6
- Modelos anteriores (Sonnet 4.5, Opus 4.5) no soportan adaptive, siguen con `budget_tokens`

**En Claude Code:**
- Ya está activo automáticamente con Opus 4.6
- Se controla indirectamente via `CLAUDE_CODE_EFFORT_LEVEL`
- El thinking también es "promptable" -- se puede guiar desde system prompt

**Probar la diferencia:**
```bash
# Terminal 1: default (high) - piensa profundo
claude

# Terminal 2: medium - balance
CLAUDE_CODE_EFFORT_LEVEL=medium claude

# Terminal 3: low - mínimo thinking, máxima velocidad
CLAUDE_CODE_EFFORT_LEVEL=low claude
```
Hacer la misma pregunta compleja en cada terminal para comparar velocidad vs calidad.

Fuente: https://platform.claude.com/docs/en/build-with-claude/adaptive-thinking

---

## Claude Code v2.1.32 - Features

### Agent Teams (research preview)

Múltiples agentes trabajando en paralelo, coordinación autónoma.

```bash
# Activar (requiere env var)
export CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1
```

- Los agentes se coordinan solos para dividir trabajo
- Mejor para: tareas que se dividen en subtareas independientes (reviews, análisis)
- Control: `Shift+Up/Down` o tmux para tomar control de subagentes
- **Cuidado**: consume muchos tokens (múltiples agentes = múltiples contextos)

### Auto-memories
- Claude guarda y recuerda memorias automáticamente mientras trabaja
- Complementa MEMORY.md manual (puede haber overlap)

### "Summarize from here"
- Compact parcial desde message selector
- Ver: `docs/cli/session-management.md` para documentación completa

### Context compaction (API, beta)
- Summarización automática del contexto cuando se acerca al límite
- Equivalente a auto-compact pero a nivel de API
- Para agentes long-running que no pueden parar a hacer `/compact`

### Otros fixes
- Skills de `--add-dir` se cargan automáticamente
- Fix heredoc con template literals `${...}` en Bash
- `--resume` re-usa `--agent` de la sesión anterior
- Skill budget escala con context window (2% del contexto)

---

## Impacto en nuestro setup

| Feature | Impacto en tooling actual |
|---------|--------------------------|
| Effort levels | Usar `medium` para tareas simples → ahorro tokens |
| Auto-memories | Puede complementar o redundar con MEMORY.md |
| Summarize from here | Complementa `/smart-compact` (manual vs automático) |
| Context compaction API | No afecta directamente (es para API developers) |
| Agent teams | Experimental, no para uso diario aún |
| 1M context | No disponible en Pro/Max, solo API premium |
